{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入資料集\n",
    "def load_mnist(path, kind='train'):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "    labels_path = os.path.join(path,'%s-labels-idx1-ubyte'% kind)\n",
    "    images_path = os.path.join(path,'%s-images-idx3-ubyte'% kind)\n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "    return images, labels\n",
    "\n",
    "X_train, y_train = load_mnist('./data', kind='train')\n",
    "X_test, y_test = load_mnist('./data', kind='t10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正規化處理\n",
    "ave_input = np.average(X_train, axis=0)\n",
    "std_input = np.std(X_train, axis=0)\n",
    "input_data = (X_train - ave_input) / std_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標籤種類\n",
    "fashion_mnist_labels = [\"T-shirt/top\",  # index 0\n",
    "                        \"Trouser\",      # index 1\n",
    "                        \"Pullover\",     # index 2 \n",
    "                        \"Dress\",        # index 3 \n",
    "                        \"Coat\",         # index 4\n",
    "                        \"Sandal\",       # index 5\n",
    "                        \"Shirt\",        # index 6 \n",
    "                        \"Sneaker\",      # index 7 \n",
    "                        \"Bag\",          # index 8 \n",
    "                        \"Ankle boot\"]   # index 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding 和切割資料\n",
    "correct_data = np.zeros((len(y_train), 10))\n",
    "\n",
    "for i in range(len(y_train)):\n",
    "    correct_data[i,y_train[i]]=1.0\n",
    "    \n",
    "n_data = len(y_train)\n",
    "(X_train, X_valid) = X_train[5000:], X_train[:5000] \n",
    "(correct_train, correct_valid) = correct_data[5000:], correct_data[:5000]\n",
    "\n",
    "n_train = X_train.shape[0] \n",
    "n_valid = X_valid.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定值\n",
    "n_in = 784  # 輸入層\n",
    "n_mid = 28 # 中間層\n",
    "n_out = 10  # 輸出層\n",
    "\n",
    "wb_width = 0.1  # 權重與偏值\n",
    "eta = 0.01  # 學習率\n",
    "epoch = 1000\n",
    "batch_size = 8\n",
    "interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 繼承來源\n",
    "class BaseLayer:\n",
    "  def __init__(self, n_upper, n):\n",
    "    self.w = wb_width * np.random.randn(n_upper, n)\n",
    "    self.b = wb_width * np.random.randn(n)\n",
    "\n",
    "    self.h_w = np.zeros(( n_upper, n)) + 1e-8\n",
    "    self.h_b = np.zeros(n) + 1e-8\n",
    "        \n",
    "  def update(self, eta):      \n",
    "    self.h_w += self.grad_w * self.grad_w\n",
    "    self.w -= eta / np.sqrt(self.h_w) * self.grad_w\n",
    "        \n",
    "    self.h_b += self.grad_b * self.grad_b\n",
    "    self.b -= eta / np.sqrt(self.h_b) * self.grad_b\n",
    "    \n",
    "# 中間層\n",
    "class MiddleLayer(BaseLayer):\n",
    "  def forward(self, x):\n",
    "    self.x = x\n",
    "    self.u = np.dot(x, self.w) + self.b\n",
    "    self.y = 0.5 * (1 + np.tanh(0.5 * self.u)) # sigmoid\n",
    "\n",
    "  def backward(self, grad_y):\n",
    "    delta = grad_y *(1-self.y)*self.y  # sigmoid的微分\n",
    "    self.grad_w = np.dot(self.x.T, delta)\n",
    "    self.grad_b = np.sum(delta, axis=0)\n",
    "    self.grad_x = np.dot(delta, self.w.T) \n",
    "    \n",
    "\n",
    "# 輸出層\n",
    "class OutputLayer(BaseLayer):     \n",
    "  def forward(self, x):\n",
    "    self.x = x\n",
    "    u = np.dot(x, self.w) + self.b\n",
    "    self.y = np.exp(u)/np.sum(np.exp(u), axis=1, keepdims=True)  # Softmax\n",
    "\n",
    "  def backward(self, t):\n",
    "    delta = self.y - t       \n",
    "    self.grad_w = np.dot(self.x.T, delta)\n",
    "    self.grad_b = np.sum(delta, axis=0)\n",
    "    self.grad_x = np.dot(delta, self.w.T) \n",
    "    \n",
    "# 丟棄層 \n",
    "class Dropout:\n",
    "  def __init__(self, dropout_ratio):\n",
    "    self.dropout_ratio = dropout_ratio  # 丟棄率\n",
    "\n",
    "  def forward(self, x, is_train):  \n",
    "    if is_train:\n",
    "      rand = np.random.rand(*x.shape)  \n",
    "      self.dropout = np.where(rand > self.dropout_ratio, 1, 0)  # 1:有効 0:無効\n",
    "      self.y = x * self.dropout  \n",
    "    else:\n",
    "      self.y = (1-self.dropout_ratio)*x\n",
    "        \n",
    "  def backward(self, grad_y):\n",
    "    self.grad_x = grad_y * self.dropout\n",
    "    \n",
    "# 各層的實體化\n",
    "middle_layer_1 = MiddleLayer(n_in, n_mid)\n",
    "dropout_1 = Dropout(0.5)\n",
    "middle_layer_2 = MiddleLayer(n_mid, n_mid)\n",
    "dropout_2 = Dropout(0.5)\n",
    "output_layer = OutputLayer(n_mid, n_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前向傳播\n",
    "def forward_propagation(x, is_train):\n",
    "  middle_layer_1.forward(x)\n",
    "  dropout_1.forward(middle_layer_1.y, is_train)\n",
    "  middle_layer_2.forward(dropout_1.y)\n",
    "  dropout_2.forward(middle_layer_2.y, is_train)\n",
    "  output_layer.forward(dropout_2.y)\n",
    "\n",
    "# 反向傳播\n",
    "def backpropagation(t):\n",
    "  output_layer.backward(t)\n",
    "  dropout_2.backward(output_layer.grad_x)\n",
    "  middle_layer_2.backward(dropout_2.grad_x)\n",
    "  dropout_1.backward(middle_layer_2.grad_x)\n",
    "  middle_layer_1.backward(dropout_1.grad_x)\n",
    "\n",
    "# 更新權重與偏值\n",
    "def uppdate_wb():\n",
    "  middle_layer_1.update(eta)\n",
    "  middle_layer_2.update(eta)\n",
    "  output_layer.update(eta)\n",
    "\n",
    "# 計算誤差\n",
    "def get_error(t, batch_size):\n",
    "  return -np.sum(t * np.log(output_layer.y + 1e-7)) / batch_size  # 交叉熵誤差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0/3000 Error_train:2.3109734287220483 Error_test:2.3116821758135897\n",
      "Epoch:100/3000 Error_train:0.9902698620666947 Error_test:1.0013541047926047\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-e0d140b10479>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m       \u001b[1;31m# 更新權重與偏值\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m       \u001b[0muppdate_wb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-9a7b0e602407>\u001b[0m in \u001b[0;36muppdate_wb\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# 更新權重與偏值\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0muppdate_wb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m   \u001b[0mmiddle_layer_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m   \u001b[0mmiddle_layer_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m   \u001b[0moutput_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-9e3561cafdab>\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, eta)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh_w\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_w\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_w\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0meta\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh_w\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_w\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "  # 記錄誤差\n",
    "  train_error_x = []\n",
    "  train_error_y = []\n",
    "  test_error_x = []\n",
    "  test_error_y = []\n",
    "    \n",
    "  # 記錄訓練進度 \n",
    "  n_batch = n_train // batch_size \n",
    "    \n",
    "  for i in range(epoch):\n",
    "    # 計算誤差  \n",
    "    forward_propagation(X_train, False)\n",
    "    error_train = get_error(correct_train, n_train)\n",
    "    forward_propagation(X_valid, False)\n",
    "    error_test = get_error(correct_valid, n_valid)\n",
    "        \n",
    "    # 記錄誤差\n",
    "    test_error_x.append(i)\n",
    "    test_error_y.append(error_test) \n",
    "    train_error_x.append(i)\n",
    "    train_error_y.append(error_train) \n",
    "        \n",
    "    # 顯示進度\n",
    "    if i%interval == 0:\n",
    "      print(\"Epoch:\" + str(i) + \"/\" + str(epoch),\n",
    "         \"Error_train:\" + str(error_train),\n",
    "         \"Error_test:\" + str(error_test))\n",
    "    \n",
    "    # 訓練 \n",
    "    index_random = np.arange(n_train)\n",
    "    np.random.shuffle(index_random)  # 索引洗牌\n",
    "    for j in range(n_batch):\n",
    "      # 取出小批次\n",
    "      mb_index = index_random[j*batch_size : (j+1)*batch_size]\n",
    "      x = X_train[mb_index, :]\n",
    "      t = correct_train[mb_index, :]\n",
    "            \n",
    "      # 前向傳播與反向傳播\n",
    "      forward_propagation(x, True)\n",
    "      backpropagation(t)\n",
    "            \n",
    "      # 更新權重與偏值\n",
    "      uppdate_wb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以圖表顯示誤差記錄\n",
    "plt.plot(train_error_x, train_error_y, label=\"Train\")\n",
    "plt.plot(test_error_x, test_error_y, label=\"Test\")\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.show()\n",
    "\n",
    "# 計算準確率  \n",
    "forward_propagation(X_train, False)\n",
    "count_train = np.sum(np.argmax(output_layer.y, axis=1) == np.argmax(correct_train, axis=1))\n",
    "\n",
    "forward_propagation(X_valid, False)\n",
    "count_test = np.sum(np.argmax(output_layer.y, axis=1) == np.argmax(correct_valid, axis=1))\n",
    "\n",
    "print(\"Accuracy Train:\", str(count_train/n_train*100) + \"%\",\n",
    "      \"Accuracy Test:\", str(count_test/n_valid*100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
